<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于SpringBoot+Nginx+Redis的电子商城（一）</title>
      <link href="2021/09/09/shopeemall/"/>
      <url>2021/09/09/shopeemall/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/09/09/shopeemall/front.png" alt="front"></p><span id="more"></span><h1 id="Readme"><a href="#Readme" class="headerlink" title="Readme"></a>Readme</h1><h2 id="Background-项目背景"><a href="#Background-项目背景" class="headerlink" title="Background 项目背景"></a>Background 项目背景</h2><p><strong>A shopeemall based on SpringBoot + Nginx + Redis</strong></p><p>此网络购物平台系统旨在为用户提供一个简易的具备一些基本功能的购物系统，通过这个系统用户可以轻松的获得自己想要的商品。存在两种类型用户，普通用户和管理员用户。普通用户在这个系统中注册过后进行登陆此时可以对个人资料进行修改，可以修改密码，同时可以在平台中进行自由的选购自己想要的商品，将选购好的商品加入购物车，如果需要修改可以在购物车中更改所需的商品数量，当选择完成过后可以确认购买，也可以让所选物品一直处在购物车中，等待下次登陆时依然有效。管理员用户可以通过管理员账号登陆后对商品进行管理，可以对商品信息进行修改，删除商品，添加新商品。前台不提供管理员用户的注册,直接在后台数据库中添加管理员用户。</p><p>本系统的目标除了提供基本购物功能和用户、订单、商品的相关管理功能之外，为了保证用户的购物体验，我们将采用Redis、Nginx及分布式技术实现服务器搭建，保证商城系统高可用性，并添加商品秒杀功能及实时热销榜功能，与实际电商系统功能贴近。</p><p>This online shopping platform system aims to provide users with a simple shopping system with some basic functions, through which users can easily obtain the goods they want. There are two types of users, ordinary users and administrator users. Ordinary users log in after registering in this system. At this time, they can modify their personal information, modify their passwords, and at the same time, they can freely choose the products they want on the platform, and add the purchased products to the shopping cart. If you need to modify, you can change the required quantity of goods in the shopping cart. After the selection is completed, you can confirm the purchase, or you can keep the selected items in the shopping cart and wait for the next login to be valid. Administrator users can manage products after logging in through the administrator account, modify product information, delete products, and add new products. The front desk does not provide the registration of the administrator user, and directly adds the administrator user in the back-end database.<br>The goal of this system is to provide basic shopping functions and related management functions for users, orders, and commodities. In order to ensure the user’s shopping experience, we will use Redis, Nginx and distributed technologies to implement server construction to ensure the high availability of the mall system, and Add product spike function and real-time hot list function, which is close to the actual e-commerce system function.</p><p><a href="https://github.com/stonehard0208/shopee-mall-based-on-Springboot-Redis-Nginx">Github</a></p><h2 id="Requirement-Analysis-需求分析"><a href="#Requirement-Analysis-需求分析" class="headerlink" title="Requirement Analysis 需求分析"></a>Requirement Analysis 需求分析</h2><h3 id="需求调查分析"><a href="#需求调查分析" class="headerlink" title="需求调查分析"></a>需求调查分析</h3><p>为了获得相关用户对于购物网站内容、形式、活动、商品等需求，我们设计了一份问卷，从用户网购需求、用户购买商品参考指标、用户年龄、网购主要原因、产生购买意愿原因、退货频率等多角度设计问卷，并面向18岁以上的用户投放问卷，总共获得问卷138份，有效问卷121份，并根据问卷结果分析用户需求，从而设计、改进网站。</p><p>以下为问卷分析结果。</p><p><img src="/2021/09/09/shopeemall/1.jpg" alt="1"></p><p>从用户网购需求饼图来看，生活用品（21%）、服饰（23%）所占比重仅次于其他（42%）之后，说明市场中用户对于服饰、生活用品的需求较高，更具有经济价值，市场空间更大，所以我们在选择商城商品内容时，更加倾向这两种，更具有实际意义。</p><p><img src="/2021/09/09/shopeemall/2.jpg" alt="2"></p><p>从用户购买商品参考指标可以看出，网页页面上最吸引用户的元素是商品图片和网购评论，其次是商品文字描述，所以在设计网站时，我们要给予商家充分的版面展示商品图片，从而激发消费者购买欲望。另外，要构建合理的网购评论、评分机制，强化好评权重，利用用户的从众心理，更容易购买。</p><p><img src="/2021/09/09/shopeemall/3.jpg" alt="3"></p><p>从用户年龄饼图来看，16-24岁（73%）人群占比最高，青少年、中年人占比较低，说明用户主力为青年人，在设计用户界面时，尽量选择明快、活泼的颜色，简洁、大方的字体，生动、功能分明的模块。</p><p><img src="/2021/09/09/shopeemall/4.jpg" alt="4"></p><p>从网购主要原因柱状图来看，方便是用户网购的最主要原因，在设计网站时应该尽量简化搜索、添加购物车、下订单、支付流程，将用户最关心的价格、折扣、款式、订单信息、物流信息显示在最明显的地方，减少用户寻找关键信息的时间。用户网购的第二原因是便宜，因此，我们将具有折扣的商品、销量极高的商品显示在主页上，吸引用户购买。</p><p><img src="/2021/09/09/shopeemall/5.jpg" alt="5"></p><p>从用户产生购买意愿的原因来看，最主要的原因是用户本身存在对商品的需求，因此，在设计网站时，可能考虑到设计商品推荐算法，对用户输入的搜索商品进行同类查找，并推荐至商品首页。第二原因是打折，和网购主要原因分析中一样，我们将具有折扣的商品、销量极高的商品显示在主页上，吸引用户购买。第三原因是商品限量，可以在商品界面上显示限量个数、存量个数，激发用户购买欲。</p><p><img src="/2021/09/09/shopeemall/6.jpg" alt="6"></p><p>从退货频率来看，62%的用户经常退货，因此，构建合理的退货评判机制、退货流程对于吸引回头客至关重要。</p><h3 id="需求获取及描述"><a href="#需求获取及描述" class="headerlink" title="需求获取及描述"></a>需求获取及描述</h3><p>根据以上问卷分析、需求分析，我们完善了中期报告中缺少的部分需求获取、需求描述。</p><p><img src="/2021/09/09/shopeemall/7.png" alt="7"></p><h3 id="参与者及用例确定"><a href="#参与者及用例确定" class="headerlink" title="参与者及用例确定"></a>参与者及用例确定</h3><p>各种用户类确认的“基于SpringBoot+Redis+Nginx的ShopeeMall商城”的主要参与者及其参与的用例如下所示：</p><p><img src="/2021/09/09/shopeemall/8.png" alt="8"></p>]]></content>
      
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Nginx </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于SpringBoot+Nginx+Redis的电子商城（二）</title>
      <link href="2021/09/09/shopeemall2/"/>
      <url>2021/09/09/shopeemall2/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/09/09/shopeemall2/front.png" alt="front"></p><span id="more"></span><h1 id="基于SpringBoot-Nginx-Redis的电子商城（二）"><a href="#基于SpringBoot-Nginx-Redis的电子商城（二）" class="headerlink" title="基于SpringBoot+Nginx+Redis的电子商城（二）"></a>基于SpringBoot+Nginx+Redis的电子商城（二）</h1><h2 id="Feasibility-analysis-可行性分析"><a href="#Feasibility-analysis-可行性分析" class="headerlink" title="Feasibility analysis 可行性分析"></a>Feasibility analysis 可行性分析</h2><h3 id="Technical-feasibility-技术可行性"><a href="#Technical-feasibility-技术可行性" class="headerlink" title="Technical feasibility 技术可行性"></a>Technical feasibility 技术可行性</h3><h4 id="（1）开发平台"><a href="#（1）开发平台" class="headerlink" title="（1）开发平台"></a>（1）开发平台</h4><p>本文系统开发使用IDEA作为后端开发工具，VSCode作为前端开发工具。IDEA作为新生代Java开发工具，非常适合开发人员操作，其友好界面以及Debug功能为用户极大地减轻开发压力。此外，本项目采用Springboot框架，POM依赖导入Jar包的时候也非常清晰简便，适合开发人员。VSCode开发工具近年来也受到一致好评，安装插件非常容易。</p><h4 id="（2）云端选择"><a href="#（2）云端选择" class="headerlink" title="（2）云端选择"></a>（2）云端选择</h4><p>本项目最终部署到云服务器当中，供用户远端访问。</p><h3 id="Organizational-feasibility-组织可行性"><a href="#Organizational-feasibility-组织可行性" class="headerlink" title="Organizational feasibility 组织可行性"></a>Organizational feasibility 组织可行性</h3><h4 id="（1）经验丰富的开发人员和指导教师"><a href="#（1）经验丰富的开发人员和指导教师" class="headerlink" title="（1）经验丰富的开发人员和指导教师"></a>（1）经验丰富的开发人员和指导教师</h4><p>本文系统的开发人员为5个软件学院18级学生，选择该系统为高级软件设计项目，在本学院就读三年中拥有良好的程序设计和开发基础，熟悉Web前端及后端开发，在有关前后端开发的课程上取得优异的成绩。本系统的指导老师为大型数据库、JavaWeb课程的任教老师，具有深厚的任教经历和开发经验，使该系统的开发具备较高的可行性。</p><h4 id="（2）合理的项目实施计划和进度安排"><a href="#（2）合理的项目实施计划和进度安排" class="headerlink" title="（2）合理的项目实施计划和进度安排"></a>（2）合理的项目实施计划和进度安排</h4><p>本文系统为学生的高级软件设计，因此在项目实施进度上有严格的保证，对项目前期需求分析和系统设计、中期程序编码和后期软件测试和论文形成均有严格的时间线进行约束和管理，具备完整的项目实施进度计划，保证项目顺利按时进行。</p><h3 id="Economic-feasibility-经济可行性"><a href="#Economic-feasibility-经济可行性" class="headerlink" title="Economic feasibility 经济可行性"></a>Economic feasibility 经济可行性</h3><h4 id="（1）项目对电商管理的价值"><a href="#（1）项目对电商管理的价值" class="headerlink" title="（1）项目对电商管理的价值"></a>（1）项目对电商管理的价值</h4><p>近年来电商行业非常火爆，电商对传统买卖交易进行了赋能，让更远的商品都能够抵达用户的手上，并且这个过程中将会减少很多中间差价，让卖家以最低的成本销售，让买家以最低的成本购入，这个过程是实惠了买卖双方，并且卖家不需要实体店就可以销售，极大减轻压力。</p><h4 id="（2）项目开销及收益"><a href="#（2）项目开销及收益" class="headerlink" title="（2）项目开销及收益"></a>（2）项目开销及收益</h4><p>本项目开发仅需租赁云服务器作为必要工具，其他工具都由项目成员自带，因此开发过程中的开销不大，而电商网站带来的效益非常之大。此外，本项目还有广告栏目，出售广告宣传位也可以为项目成员带来一定的收益。因此从经济的可行性分析来看是没问题的。</p><h2 id="Project-designing-项目设计"><a href="#Project-designing-项目设计" class="headerlink" title="Project designing 项目设计"></a>Project designing 项目设计</h2><h3 id="概要设计"><a href="#概要设计" class="headerlink" title="概要设计"></a>概要设计</h3><h4 id="使用技术、开发环境"><a href="#使用技术、开发环境" class="headerlink" title="使用技术、开发环境"></a>使用技术、开发环境</h4><p>在本次项目开发中，我们所应用到与高级实作课程教学相关的技术及其在本项目的作用介绍如下（部分基础、必不可少的技术暂不介绍）：</p><p><img src="/2021/09/09/shopeemall2/1.png" alt="1"></p><p><img src="/2021/09/09/shopeemall2/2.png" alt="2"></p><h4 id="系统部署设计"><a href="#系统部署设计" class="headerlink" title="系统部署设计"></a>系统部署设计</h4><p>项目采用线上部署，系统结构如图所示，我们使用一台安装nginx的负载均衡服务器按照配置好的规则将请求分发到两台tomcat服务器上，tomcat服务器之间配置数据库的主主同步，同时共同使用另一台服务器上的redis服务，保证了数据的一致性。nginx服务器同时也作为静态资源服务器，完成两台tomcat服务器访问静态资源及上传文件的功能。</p><p>由于Nginx配置包含ip_hash，因此用户在设备不变时只能访问一台特定的tomcat服务器，当ip地址改变时，可能就会访问另一个tomcat服务器。如果遇到第一个服务器SERVER-1不能提供服务的情况，将通过nginx的宕机轮询机制，由第二台tomcat服务器SERVER-2进行访问，这样就提高了系统的可用性。</p><p>系统部署拓扑图如下所示：</p><p><img src="/2021/09/09/shopeemall2/3.png" alt="2"></p><h3 id="系统及模块分析"><a href="#系统及模块分析" class="headerlink" title="系统及模块分析"></a>系统及模块分析</h3><h4 id="系统整体分析"><a href="#系统整体分析" class="headerlink" title="系统整体分析"></a>系统整体分析</h4><p><img src="/2021/09/09/shopeemall2/4.jpg" alt="4"></p><p><img src="/2021/09/09/shopeemall2/5.jpg" alt="5"></p><h4 id="登录注册模块分析"><a href="#登录注册模块分析" class="headerlink" title="登录注册模块分析"></a>登录注册模块分析</h4><p><img src="/2021/09/09/shopeemall2/6.png" alt="6"></p><p><img src="/2021/09/09/shopeemall2/7.png" alt="7"></p><h4 id="商品浏览模块分析"><a href="#商品浏览模块分析" class="headerlink" title="商品浏览模块分析"></a>商品浏览模块分析</h4><p><img src="/2021/09/09/shopeemall2/8.png" alt="6"></p><p><img src="/2021/09/09/shopeemall2/9.png" alt="7"></p><h4 id="订单管理模块分析"><a href="#订单管理模块分析" class="headerlink" title="订单管理模块分析"></a>订单管理模块分析</h4><p><img src="/2021/09/09/shopeemall2/10.png" alt="7"></p><h3 id="功能设计"><a href="#功能设计" class="headerlink" title="功能设计"></a>功能设计</h3><p>网上商城共分两个部分，一部分是面向用户的部分，包括：顾客在线注册、购物、提交订单、付款等操作；另外一部分是商城管理部分，这部分的内容包括：产品的添加、删除、查询、订单的管理、操作员的管理、注册用户的管理等。</p><p><img src="/2021/09/09/shopeemall2/11.png" alt="7"></p><h4 id="前台普通用户功能设计"><a href="#前台普通用户功能设计" class="headerlink" title="前台普通用户功能设计"></a>前台普通用户功能设计</h4><p><img src="/2021/09/09/shopeemall2/12.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/13.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/14.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/15.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/16.png" alt="7"></p><h4 id="后台管理员功能设计"><a href="#后台管理员功能设计" class="headerlink" title="后台管理员功能设计"></a>后台管理员功能设计</h4><p><img src="/2021/09/09/shopeemall2/17.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/18.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/19.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/20.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/21.png" alt="7"></p><h3 id="详细设计"><a href="#详细设计" class="headerlink" title="详细设计"></a>详细设计</h3><h4 id="数据库设计"><a href="#数据库设计" class="headerlink" title="数据库设计"></a>数据库设计</h4><p>MySQL作为主存储，存储持久化数据。市场上流行的 持久化数据库主要有 Oracle、SYBASE、MySQL、DB2、Informix等，而MySQL可作为中小型数据管理系统的首选。根据以上分析，本系统后台持久化数据库决定采用MySQL 为后台数据库。</p><h4 id="数据库概念设计"><a href="#数据库概念设计" class="headerlink" title="数据库概念设计"></a>数据库概念设计</h4><p><img src="/2021/09/09/shopeemall2/22.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/23.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/24.png" alt="7"></p><h4 id="数据库逻辑设计"><a href="#数据库逻辑设计" class="headerlink" title="数据库逻辑设计"></a>数据库逻辑设计</h4><p><img src="/2021/09/09/shopeemall2/25.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/26.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/27.png" alt="7"></p><p><img src="/2021/09/09/shopeemall2/28.png" alt="7"></p>]]></content>
      
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Nginx </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于风格迁移的AI绘画大师</title>
      <link href="2021/04/21/style-transfer-AI-painting/"/>
      <url>2021/04/21/style-transfer-AI-painting/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/21/style-transfer-AI-painting/front.jpeg" alt="front"></p><span id="more"></span><h1 id="Readme"><a href="#Readme" class="headerlink" title="Readme"></a>Readme</h1><h2 id="Background-项目背景"><a href="#Background-项目背景" class="headerlink" title="Background 项目背景"></a>Background 项目背景</h2><p>This project is an AI painting master based on the Pytorch framework and style transfer technology. It mainly refers to the <a href="https://www.pytorchtutorial.com/pytorch-style-transfer/">Pytorch tutorial</a> and the paper <a href="https://arxiv.org/abs/1508.06576">A Neural Algorithm of Artistic Style</a>.<br>In addition, compared to the original thesis tutorial, we have made certain modifications to the model structure to make the visual effect better.</p><p>本项目是基于Pytorch框架，风格迁移技术的AI绘画大师，主要参考了Pytorch官方tutorial中的<a href="https://www.pytorchtutorial.com/pytorch-style-transfer/">教程</a>和论文<a href="https://arxiv.org/abs/1508.06576">A Neural Algorithm of Artistic Style</a>。<br>另外，相比于原论文教程，我们在模型结构上做出了一定的修改，使得视觉效果更好。</p><p><a href="https://github.com/stonehard0208/Style-transfer-AI-painting">Github</a></p><h2 id="Preview-效果预览"><a href="#Preview-效果预览" class="headerlink" title="Preview 效果预览"></a>Preview 效果预览</h2><p><img src="/2021/04/21/style-transfer-AI-painting/1.JPG" alt="1"><br><img src="/2021/04/21/style-transfer-AI-painting/2.JPG" alt="2"><br><img src="/2021/04/21/style-transfer-AI-painting/3.JPG" alt="3"><br><img src="/2021/04/21/style-transfer-AI-painting/4.JPG" alt="4"><br><img src="/2021/04/21/style-transfer-AI-painting/5.JPG" alt="5"><br><img src="/2021/04/21/style-transfer-AI-painting/6.JPG" alt="6"></p><h2 id="Innovation-创新点"><a href="#Innovation-创新点" class="headerlink" title="Innovation 创新点"></a>Innovation 创新点</h2><h3 id="1-Modify-the-content-layer-修改内容层"><a href="#1-Modify-the-content-layer-修改内容层" class="headerlink" title="1. Modify the content layer 修改内容层"></a>1. Modify the content layer 修改内容层</h3><p>The original paper used conv_4 as the content layer. We used conv_4, conv_5, conv_6, and conv_7 as the content layer. Although it is not reflected in the data result, it has a better visual effect.</p><p>原论文以conv_4作为内容曾，我们将conv_4,conv_5,conv_6,conv_7作为内容层，虽然在数据上体现不大，但是在肉眼可见的视觉方面效果更好。</p><p><img src="/2021/04/21/style-transfer-AI-painting/17.JPG" alt="1"><br><img src="/2021/04/21/style-transfer-AI-painting/18.JPG" alt="1"><br><img src="/2021/04/21/style-transfer-AI-painting/19.JPG" alt="1"></p><p>It can be clearly found that choosing conv_4, conv_5, conv_6, and conv_7 as the content layer, the overall style of the image does not change much, but the details are clearer.</p><p>可以明显发现，选用conv_4,conv_5,conv_6,conv_7作为内容层，图像整体风格变化不大，但是细节方面更加清晰。</p><h3 id="2-Modify-the-Optimizer-修改优化器"><a href="#2-Modify-the-Optimizer-修改优化器" class="headerlink" title="2. Modify the Optimizer 修改优化器"></a>2. Modify the Optimizer 修改优化器</h3><p>The original paper used L-BFGS as the optimizer. In the actual operation, we found that it was slower and completely changed the color of the original image and modified it to the Adam optimizer.</p><p>原论文使用L-BFGS作为优化器，在实际运行过程中，我们发现其速度较慢，且完全改变了原图的颜色，修改为Adam优化器。</p><p><img src="/2021/04/21/style-transfer-AI-painting/20.JPG" alt="1"><br><img src="/2021/04/21/style-transfer-AI-painting/21.JPG" alt="1"></p><h3 id="3-Modify-the-loss-function-修改损失函数"><a href="#3-Modify-the-loss-function-修改损失函数" class="headerlink" title="3. Modify the loss function 修改损失函数"></a>3. Modify the loss function 修改损失函数</h3><p>The original paper uses MSE_LOSS for calculation. After consulting many documents, we found that in the style transfer project, the effect of L1_loss may be better than L2_loss (MSE_loss), so we tried.</p><p>原文中使用MSE_LOSS用于计算，我们在查阅许多资料文献后发现，在风格迁移这个项目中，L1_loss的效果可能比L2_loss（MSE_loss）效果更好，故进行了尝试。</p><p><img src="/2021/04/21/style-transfer-AI-painting/22.JPG" alt="1"></p><p>Obviously, looking at the picture, it can be seen that L1_Loss is not sensitive to outliers, and when we perform style transfer, we do not need to completely integrate the features of the style picture with the content picture. In many cases, keeping some of the content picture features is more effective, so we hope to keep some outliers.</p><p>显然，看图可以得知，L1_Loss对于离群点并不敏感，而我们在进行风格迁移的时候，并不需要完全将风格图片的特征与内容图片融合，很多时候保留部分内容图片特征反而效果更好，所以希望保留一些离群点。</p><p><img src="/2021/04/21/style-transfer-AI-painting/23.JPG" alt="1"></p><p>效果如图</p><p><img src="/2021/04/21/style-transfer-AI-painting/24.JPG" alt="1"><br><img src="/2021/04/21/style-transfer-AI-painting/25.JPG" alt="1"></p><h2 id="Code-代码解读"><a href="#Code-代码解读" class="headerlink" title="Code 代码解读"></a>Code 代码解读</h2><p><img src="/2021/04/21/style-transfer-AI-painting/8.JPG" alt="1"></p><p>导入图片</p><p><img src="/2021/04/21/style-transfer-AI-painting/9.JPG" alt="2"></p><p>修改图片大小，风格迁移算法要求两张图片大小一致</p><p><img src="/2021/04/21/style-transfer-AI-painting/10.JPG" alt="3"></p><p>计算内容差异</p><p><img src="/2021/04/21/style-transfer-AI-painting/11.JPG" alt="4"></p><p>计算风格差异</p><p><img src="/2021/04/21/style-transfer-AI-painting/12.JPG" alt="5"></p><p>设定gram矩阵</p><p><img src="/2021/04/21/style-transfer-AI-painting/13.JPG" alt="6"></p><p>Normalizing</p><p><img src="/2021/04/21/style-transfer-AI-painting/14.JPG" alt="6"></p><p>此处设定对于实现的图像细节视觉效果来说非常重要，相比于原论文，我们这里做了修改，使得视觉效果更好。</p><p><img src="/2021/04/21/style-transfer-AI-painting/16.JPG" alt="6"><br><img src="/2021/04/21/style-transfer-AI-painting/15.JPG" alt="6"></p><p>训练模型</p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> style-transfer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安卓开发：具有天气预报功能的记事本APP （二）天气预报</title>
      <link href="2021/04/21/notebook-with-weatherforcast2/"/>
      <url>2021/04/21/notebook-with-weatherforcast2/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/21/notebook-with-weatherforcast2/1.png" alt="1"></p><span id="more"></span><h2 id="接上文"><a href="#接上文" class="headerlink" title="接上文"></a>接上文</h2><p><a href="http://chayacy.top/2021/04/21/notebook-with-weatherforcast/"> 安卓开发：具有天气预报功能的记事本APP （一）记事本</a></p><h2 id="天气功能-Weather-forecast-function"><a href="#天气功能-Weather-forecast-function" class="headerlink" title="天气功能 Weather forecast function"></a>天气功能 Weather forecast function</h2><p>XML文件：activity_weather和weather_item。</p><p>activity_weather是天气界面的布局，上方为一个actionBar，actionbar中有返回主页按钮、“天气”字样，下方为一个textView和一个ListView，textView显示当前城市，ListView用于存放天气相关信息。</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/f2960519140313f45d7b155cc146c258.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/d008a84afe4c32552fc83d9ea5c56708.png"></p><p>Weather_item中有五个TextView，分别用来存放date,text_day,text_night,high,low。（日期，晨间天气，夜间天气，最高气温，最低气温）</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/ccf5dcaa3d4f20a4f72f966720d2091a.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/44c926ab70dfb35d242fa391c385cf28.png"></p><p>Java文件：WeatherInfo Weather JsonParser</p><p>WeatherInfo中写了date,text_day,text_night,high,low六个属性的setter和getter。</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/0857fc89ab67b8109eaea55e219f5370.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/da681aa19180c84f939f44814a8506be.png"></p><p>JsonParser用于解析心知天气api的信息</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/380a355a83f097fdb8b7efc003f33c02.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/fb20151ae0338bb6478b35c97d02d59a.png"></p><h2 id="使用到的API接口："><a href="#使用到的API接口：" class="headerlink" title="使用到的API接口："></a>使用到的API接口：</h2><p>在WeatherInfo中，有city,date,text_day,text_night,high,low六个属性，以及setter<br>getter函数，这六个属性是要从seniverse心知天气这个api中获得的属性。</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/86363436d31cb6a14df23ac981fad773.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/2292cab726dba6acec618093a5f7da17.png"></p><p>在JsonParser中，创建一个arrayList，用于填入天气的相关信息。创建WeatherInfo类变量weatherInfo，并设置weatherInfo的city属性，根据不同的city调用api,并通过JsonArray、JSONObject来解析api中的信息，并获得该城市的date,<br>text_day,text_night,high,low。</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/3d22f0c8a5b3d8c331412259eccbaf2f.png"></p><p>获得JsonArray后，通过遍历，取出的每一个元素都是JsonObject对象，每个JsonObject对象里都会包含date,text_daty,text_night,high,low数据，调用getString即可取出这些数据。<img src="/2021/04/21/notebook-with-weatherforcast2/7e241328adaaa6d31f98717b00868192.png"></p><p>在weather中，设定的默认city为beijing，并将city填于url中，利用心知天气的链接获取北京的天气数据，并将数据以String的形式填入arrayList。<img src="/2021/04/21/notebook-with-weatherforcast2/3a4790658707870130c8ee16d27ede8d.png"></p><p>这里我们使用了HttpURLConnection发起HTTP请求，并解析服务器返回的数据<img src="/2021/04/21/notebook-with-weatherforcast2/3a4790658707870130c8ee16d27ede8d.png"></p><p>Weather的内部类Adapter继承了BaseAdapter，在getView函数中，使用inflate找到weather_item，并通过findViewById函数，获取date,text_day,text_night,high,low的TextView，再将arrayList中的数据利用setText传入TextView中显示。</p><p><img src="/2021/04/21/notebook-with-weatherforcast2/9cf8585f41f63dcd8ad9994cecbc3cb1.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/9518f2ed84a5882299e0d4a35ea3ca83.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast2/18fe0ae0dfce2e26d3d4f0e344a9ddfc.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安卓开发：具有天气预报功能的记事本APP （一）记事本</title>
      <link href="2021/04/21/notebook-with-weatherforcast/"/>
      <url>2021/04/21/notebook-with-weatherforcast/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/21/notebook-with-weatherforcast/1.jpg" alt="1"></p><span id="more"></span><h2 id="本项目Github"><a href="#本项目Github" class="headerlink" title="本项目Github"></a>本项目Github</h2><p><a href="https://github.com/stonehard0208/notebook-with-weatherforecast">Github</a></p><h1 id="代码解读-Code-interpretation"><a href="#代码解读-Code-interpretation" class="headerlink" title="代码解读 Code interpretation"></a>代码解读 Code interpretation</h1><h2 id="记事本功能-NoteBook-funuction"><a href="#记事本功能-NoteBook-funuction" class="headerlink" title="记事本功能 NoteBook funuction"></a>记事本功能 NoteBook funuction</h2><p>包含两个部分，一个是部分单纯的文本记录功能，还有一个是每一个笔记的提醒时间设置功能。每一个笔记的id、标题、内容和提醒时间等相关信息都作为Note类的属性进行存放。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/47c5aed36e2b261075828252a9f541ea.png" alt="1592176561(1)"></p><p>SQLite数据库中表的创建也是按照Note类的属性的。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/e210605ff2898ccd08e507116c928a43.png" alt="1592176932(1)"></p><p>用户点击首页右上角的“+”号创建笔记，笔记的创建需要用户输入标题和内容，提醒时间如果没有设置就会使用默认的提醒时间，提交笔记保存后会判断笔记输入的内容是否为空，即文本长度为0，然后将输入的内容封装成Note类型的对象，然后调用SimpleDatabase类中的addNote方法，传递参数为Note对象，使用ContentValues<br>插入数据，每一个笔记的id属性都是由插入数据库中存储后才产生并返回的，id是唯一的所以可以根据笔记的id进行查找。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/a4250574ae8c07be4f58f1d8535ed4f3.png" alt="1592176879(1)"><img src="/2021/04/21/notebook-with-weatherforcast/e2334b8f59021061425c7e0e56dd6e02.png"></p><p>首页展示用户的已有的笔记列表时会使用List&lt;Note&gt;存储从数据库查找的所有已经创建保存的笔记。如果用户还没有保存过笔记，即List&lt;Note&gt;是空的，就展示activity_main.xml中TextView“未记过笔记，请点右上方+进行创建”的提示信息。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/d467c79d939c6e993b61815526992341.png" alt="1592177673(1)"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/531a58d21f47e55c66d530aaf9045aaa.png" alt="1592177819(1)"></p><p>如果搜寻结果不为空，即用户记录过笔记，就用displayList方法将List&lt;Note&gt;传递进去，借助RecyclerView、Adapter显示数据。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/27ca9797c395f1f620f18f1a054a69d9.png" alt="1592177959(1)"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/95a5d7c8f7c3fd62be93056134a0387a.png" alt="1592178238"></p><p>首页中笔记的显示还要添加被选时允许展示笔记详情内容的事件，用的是itemView的setOnClickListener，点击后会跳转到对应笔记的内容显示，用户的是笔记的ID属性进行Activity的跳转。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/b510802023d1529c91cf26e43e415149.png" alt="1592178736(1)"></p><p>其中一个重要的方法是通过id获取笔记，利用id作为数据库查找的依据。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/1bf4e6b05a238eb55b15fa11e035d7f1.png"></p><p>此时界面右下方的FloatingActionButton提供了删除功能，设置的点击事件为笔记删除，用的是SimpleDatabase的deleNote方法，传入了Note对象的id属性进行删除，并且用Toast提醒用户笔记已经被删除的信息。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/078105eed1abfaa69774d35441750231.png" alt="1592178849(1)"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/57e02167c58e63e2a5927fa94e54f5ee.png" alt="1592178803(1)"></p><p>笔记详情展示界面还有允许用户编辑修改的功能，编辑按钮在Toolbar上面的Menu中，如果选择的是edit的item就要跳转到编辑界面，这个界面与笔记创建界面几乎相同，但是完成编辑后调用的是SimpleDatabase的editNote方法，同样是传入将笔记的id、标题、时间、内容等信息封装而成的对象，在数据库中的更新也是借助笔记的id进行的。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/e2bb2f26a5eebb17d0bcfcfb020c2c22.png" alt="1592179042(1)"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/794b2dbbf2a9ec5b5135c464a707d0e1.png" alt="1592179204(1)"></p><h2 id="闹钟提醒功能-Clock-function"><a href="#闹钟提醒功能-Clock-function" class="headerlink" title="闹钟提醒功能 Clock function"></a>闹钟提醒功能 Clock function</h2><p>ClockManager类中存放的是获取系统闹钟服务、取消闹钟以及添加脑中的服务，在添加闹钟与更新闹钟均使用addAlarm函数，在函数中，添加闹钟前，如果已经添加过闹钟，则该闹钟被取消。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/5183aa28cea9fad0ac368082da3ea3cb.png"></p><p>在名字为edit和add_note的xml文件中，添加了提醒时间框。</p><p><img src="/2021/04/21/notebook-with-weatherforcast/fa946ecf8e35b59e8964f9e73781d6d9.png"></p><p>在EditText中设置参数，让其不可输入但是可以点击</p><p><img src="/2021/04/21/notebook-with-weatherforcast/9583122a81511bdf2423f165a7d30e04.png"></p><p>在add_note类中datePickClick在点击该EditText的时候被调用。弹出时间选择器供用户选择时间</p><p><img src="/2021/04/21/notebook-with-weatherforcast/14d97e1e74e0a7df111566ad2ebb97cd.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/278615db5b1982ddcf045d5713263817.jpeg" alt="cce31264977b20b35cf20d5c619722c"></p><p>点击保存后，以下代码会在系统中添加闹钟用于提醒</p><p><img src="/2021/04/21/notebook-with-weatherforcast/7245fa8ff1a0c68ef551851a859d65ca.png"></p><p>到时间后，ClockReceive会接收到广播，onReceive函数接收到广播后调用postToClockActivity函数来启动ClockActivity类，ClockActivity调用函数clock（）；</p><p><img src="/2021/04/21/notebook-with-weatherforcast/d4bec1a5de66515391c9f0681f7e4c27.png"></p><p><img src="/2021/04/21/notebook-with-weatherforcast/6694a6b40ec845fb7b676f19e6358d97.png"></p><p>弹出dialog_alarm_layout布局，用于提醒用户事件未完成</p><p><img src="/2021/04/21/notebook-with-weatherforcast/bd08f712c854383e1f8cf9d19f079d90.jpeg" alt="0194ac593952ca6dc17f4ce3b24ec54"></p><p>函数中以下三个函数让提醒的界面有闹铃声音以及震动</p><p><img src="/2021/04/21/notebook-with-weatherforcast/149fd1f724e076cc733b86b990cc0ac9.png"></p><p>如果屏幕没有唤醒则调用wakeUpAndUnlock函数</p><p><img src="/2021/04/21/notebook-with-weatherforcast/1161755308813e2fb6b9cb81b094ebce.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Android </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于深度学习的人体行为视频识别项目 （一）数据处理</title>
      <link href="2021/04/19/human-action-video-recognition/"/>
      <url>2021/04/19/human-action-video-recognition/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/19/human-action-video-recognition/front.png" alt="front"></p><span id="more"></span><h1 id="Readme"><a href="#Readme" class="headerlink" title="Readme"></a>Readme</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>This project is a video behavior recognition project based on deep learning. It mainly contains three modules, including a player module, an output log module, and a model training module. Reading this document you can know the following:</p><ol><li>How to divide the data set into training set and test set proportionally? (Take UCF101 as an example)</li><li>How to convert a video data set to a picture data set?</li><li>How to call Pytorch’s own pre-training model training pictures?</li><li>How to modify the pre-training model?(Take Inception-v3 as an example)</li><li>How to make a player software with the function of recognizing human behavior video?</li></ol><hr><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>  本项目是基于深度学习的视频行为识别项目，主要含有三个模块，包括播放器模块、输出日志模块、模型训练模块。查阅本文档你可以得知以下内容：</p><ol><li>如何按比例分割数据集为训练集与测试集？（以UCF101为例）</li><li>如何将视频数据集转为图片？</li><li>如何调用Pytorch自带的预训练模型训练图片？</li><li>如何修改预训练模型（以Inception-v3为例）？</li><li>如何制作一个具有识别人体行为视频功能的播放器软件？</li></ol><h2 id="参考项目"><a href="#参考项目" class="headerlink" title="参考项目"></a>参考项目</h2><p><a href="https://zhuanlan.zhihu.com/p/28307781">知乎</a><br><a href="https://github.com/sujiongming/UCF-101_video_classification">Github</a></p><p>感谢大佬！</p><h2 id="本项目Github"><a href="#本项目Github" class="headerlink" title="本项目Github"></a>本项目Github</h2><p><a href="https://github.com/stonehard0208/video-recognition-Pytorch-Windows">Github</a></p><!--more--><h2 id="Preview-效果预览"><a href="#Preview-效果预览" class="headerlink" title="Preview 效果预览"></a>Preview 效果预览</h2><p>  这个项目做的比较早了，当时没有系统学过Qt前端，所以界面丑一点哈哈，看一下效果就行了</p><h3 id="Homepage-播放器主界面"><a href="#Homepage-播放器主界面" class="headerlink" title="Homepage 播放器主界面"></a>Homepage 播放器主界面</h3><p>  <img src="/2021/04/19/human-action-video-recognition/1.JPG" alt="1"></p><p>  The left side is the video preview, you can drag the progress bar to watch, you can also pause the playback, and the right box can output the identification log.</p><p>  左侧为视频预览，可以拖动进度条观看，可以暂停播放，右侧方框可以输出识别日志。</p><h3 id="上传视频-amp-识别结果"><a href="#上传视频-amp-识别结果" class="headerlink" title="上传视频 &amp; 识别结果"></a>上传视频 &amp; 识别结果</h3><p>  <img src="/2021/04/19/human-action-video-recognition/2.JPG" alt="2"><br>  <img src="/2021/04/19/human-action-video-recognition/3.JPG" alt="3"><br>  <img src="/2021/04/19/human-action-video-recognition/4.JPG" alt="4"><br>  <img src="/2021/04/19/human-action-video-recognition/5.JPG" alt="5"></p><p>  These video actions are all human actions in the UCF101 data set. The first video comes from UCF101 training set, and the latter two are recorded by ourselves and are not included in the data set. The above three video recognition results are all correct.</p><p>  这些视频动作均为UCF101数据集中的人体动作类，其中第一个视频为训练集中的视频，后两个为我们自己录制，不包含在数据集中，用于测试的视频。以上三个视频识别结果均正确。</p><h2 id="Code-interpretation-代码解读"><a href="#Code-interpretation-代码解读" class="headerlink" title="Code interpretation 代码解读"></a>Code interpretation 代码解读</h2><h3 id="Split-the-video-data-set-分割视频数据集"><a href="#Split-the-video-data-set-分割视频数据集" class="headerlink" title="Split the video data set 分割视频数据集"></a>Split the video data set 分割视频数据集</h3><p>  UCF101 officially provides a txt file for dividing the video data set into train set and test set. We only need to read the file list and process it on the string to obtain the file names in the training set and test set, and then use Functions in python to create folders and move videos.</p><p>  UCF101官方提供了txt文件用于分割视频数据集为训练集和测试集，我们只需要读取文件列表，并对其进行字符串上的处理，从而获得训练集和测试集中的文件名称，再使用python中函数创建文件夹、移动视频即可。</p><p><img src="/2021/04/19/human-action-video-recognition/6.JPG" alt="6"></p><p><img src="/2021/04/19/human-action-video-recognition/7.JPG" alt="7"></p><p>group_list函数中，首先获取参数version，该参数代表读取的是ucfTrainTestlist中的哪一个组合，总共有01、02、03三种组合。</p><p>利用strip、split等字符串操作，读取每一个视频路径，获得的train_list、test_list为列表，列表中每一项格式如下，以此类推。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</span><br></pre></td></tr></table></figure><p>group是包含了train_list和test_list的字典。</p><p><img src="/2021/04/19/human-action-video-recognition/8.JPG" alt="8"></p><p>move_data的参数为上面获得的group，在函数中，首先对group中字符串进行分析，获得动作名和视频文件名，并利用python中函数创建文件夹，移动视频。以ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi为例子。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这是group中trainlist列表中的第一项</span></span><br><span class="line">ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    file = &#x27;train&#x27;,&#x27;test&#x27;</span></span><br><span class="line"><span class="string">    videos = train_list,test_list</span></span><br><span class="line"><span class="string">    (以第一项为例)</span></span><br><span class="line"><span class="string">    name = [&#x27;ApplyEyeMakeup&#x27;,&#x27;v_ApplyEyeMakeup_g08_c01.avi&#x27;]</span></span><br><span class="line"><span class="string">    classname = ApplyEyeMakeup</span></span><br><span class="line"><span class="string">    filename = v_ApplyEyeMakeup_g08_c01.avi</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>     </span><br><span class="line"><span class="keyword">for</span> file,videos <span class="keyword">in</span> group.items():</span><br><span class="line">    <span class="keyword">for</span> real_video <span class="keyword">in</span> videos:</span><br><span class="line">        name = real_video.split(<span class="string">&#x27;/&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        classname = name[<span class="number">0</span>]</span><br><span class="line">        filename = name[<span class="number">1</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    确认路径：</span></span><br><span class="line"><span class="string">    train/ApplyEyeMakeup(文件夹是否存在，如果不存在，则创建)</span></span><br><span class="line"><span class="string">    test/ApplyEyeMakeup(文件夹是否存在，如果不存在，则创建)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    确认路径：</span></span><br><span class="line"><span class="string">    ./ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi是否存在，</span></span><br><span class="line"><span class="string">    如果UCF101中存在该文件，才可以继续，接下来的复制。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file + <span class="string">&#x27;/&#x27;</span> + classname):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Creating folder for %s/%s&quot;</span> %(file, classname))</span><br><span class="line">            os.makedirs(file + <span class="string">&#x27;/&#x27;</span> + classname)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&#x27;./&#x27;</span> + classname + <span class="string">&#x27;/&#x27;</span> + filename):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;/&#x27;</span> + classname + <span class="string">&#x27;/&#x27;</span> + filename)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Can&#x27;t find %s.&quot;</span> % (filename))</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    dest为目标目录：</span></span><br><span class="line"><span class="string">    train/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</span></span><br><span class="line"><span class="string">    test/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    original为原地址</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">        dest = file + <span class="string">&#x27;/&#x27;</span> + classname + <span class="string">&#x27;/&#x27;</span> + filename</span><br><span class="line">            <span class="comment">#print(dest)</span></span><br><span class="line">            original = os.path.join(classname, filename)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Moving %s to %s&quot;</span> % (filename, dest))</span><br><span class="line">            os.rename(original, dest)</span><br></pre></td></tr></table></figure><p>以上操作后可以获得两个文件夹，train和test，目录结构如下：</p><p><img src="/2021/04/19/human-action-video-recognition/10.JPG" alt="10"><br><img src="/2021/04/19/human-action-video-recognition/11.JPG" alt="11"></p><p>使用函数将空余文件夹删除</p><p><img src="/2021/04/19/human-action-video-recognition/12.JPG" alt="12"></p><p>就此，我们成功将训练集与测试集分开，接下来要对视频进行解帧，从而获得图片。</p><h3 id="Use-ffmpeg-deframe-videos-into-pictures"><a href="#Use-ffmpeg-deframe-videos-into-pictures" class="headerlink" title="Use ffmpeg deframe videos into pictures"></a>Use ffmpeg deframe videos into pictures</h3><h3 id="视频解帧为图片"><a href="#视频解帧为图片" class="headerlink" title="视频解帧为图片"></a>视频解帧为图片</h3><p><img src="/2021/04/19/human-action-video-recognition/13.JPG" alt="13"></p><p>见图片代码注释可知，get_video_name函数可以返回四个值，分别是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_test:视频来源于训练集or测试集</span><br><span class="line">classname:ApplyEyeMakeup</span><br><span class="line">filename_no_dot:v_ApplyEyeMakeup_g08_c01</span><br><span class="line">filename:v_ApplyEyeMakeup_g08_c01.avi</span><br></pre></td></tr></table></figure><p><img src="/2021/04/19/human-action-video-recognition/14.JPG" alt="14"></p><p>接下来的conver函数将调用以上两个函数用于确认是否存在图片，以及创建文件夹。</p><p><img src="/2021/04/19/human-action-video-recognition/15.JPG" alt="15"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27; file:train/test</span></span><br><span class="line"><span class="string">    search_folders: 列表 第一项：ApplyEyeMakeup</span></span><br><span class="line"><span class="string">    avi_file: 列表 第一项：v_ApplyEyeMakeup_g08_c01.avi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    src = train/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi </span></span><br><span class="line"><span class="string">    jpg_path = train/ApplyEyeMakeup/</span></span><br><span class="line"><span class="string">    dest = train/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01_00001.jpg</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    call函数调用ffmpeg，这里参数1的意思是每一秒抽取一帧</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>获得的文件结构如下：</p><p><img src="/2021/04/19/human-action-video-recognition/10.JPG" alt="10"><br><img src="/2021/04/19/human-action-video-recognition/11.JPG" alt="11"><br><img src="/2021/04/19/human-action-video-recognition/16.JPG" alt="16"></p><p>至此，我们已经完成了数据预处理的基本操作，接下来开始是训练模型部分。因为接下来的训练只会使用到图片，所以要将train和test中的视频手动删除。</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> deep-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于深度学习的人体行为视频识别项目 （二）模型训练</title>
      <link href="2021/04/19/human-action-video-recognition2/"/>
      <url>2021/04/19/human-action-video-recognition2/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/19/human-action-video-recognition2/front.jpg" alt="front"></p><span id="more"></span><h2 id="接上文"><a href="#接上文" class="headerlink" title="接上文"></a>接上文</h2><p><a href="http://chayacy.top/2021/04/19/human-action-video-recognition/"> 基于深度学习的人体行为视频识别项目 （一）数据处理</a></p><h3 id="Model-Training-模型训练"><a href="#Model-Training-模型训练" class="headerlink" title="Model Training 模型训练"></a>Model Training 模型训练</h3><p><img src="/2021/04/19/human-action-video-recognition2/17.JPG" alt="17"></p><p>使用Pytorch中的DataLoader导入，前面之所以设置那样的文件目录是因为这是DataLoader的要求，详见<a href="https://pytorch.org/docs/stable/data.html">Pytorch官方文档</a>。</p><p>Resize(299,299)是模型Inception-v3的需要。</p><p>batch_size = 64是我们根据实验获得的最佳超参数，可以根据实际个人配置进行调整。</p><p><img src="/2021/04/19/human-action-video-recognition2/18.JPG" alt="18"></p><!--more--><p>在get_model函数中调用inception-v3，并添加两个线性全连接层，添加Dropout和LeakyRelu防止过拟合。<br>这里仅仅做了最简单的修改，Pytorch预训练模型自由度很高，支持屏蔽某些层等更高级的修改。</p><p>最后一个Linear的最后一个参数应该为动作类别的数量，可以通过读取文件夹个数获取，这里直接写101是因为UCF101总共101个动作，偷了个懒XD</p><p>之后的训练过程和图像识别基本一致，这里简单解释，详情可以参照<a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html">Pytorch官方案例</a>。</p><p><img src="/2021/04/19/human-action-video-recognition2/19.JPG" alt="19"></p><p>定义模型，device，optimizer等，optimizer类型和learning_rate均可以修改。</p><p><img src="/2021/04/19/human-action-video-recognition2/20.JPG" alt="20"></p><p>训练阶段，注释部分可以保存模型state，中途停止后可以读取State继续运行。</p><p><img src="/2021/04/19/human-action-video-recognition2/21.JPG" alt="21"></p><p>上面这张图片读取了state，这样我们一旦停止训练，下一次无需从Epoch=1开始，state中已经保存了相关参数。</p><p><img src="/2021/04/19/human-action-video-recognition2/22.JPG" alt="22"></p><p>验证部分。<br>实际上真正过程中应该分为Training,Testing,和Validation，但是由于UCF101官方给的文件仅区分了training和testing，且作者做这个项目的时候对于深度学习不甚了解，所以本项目中没有区分testing和validation。</p><p>至此，训练和验证部分结束，每一个Epoch我们均保存了参数，挑选最佳参数读取即可。接下来将进入软件开发部分。</p><hr><p>前端部分参照各大Qt教程即可，这里简单写一下如何使用我们训练获得的参数，如何用来识别自己录制的视频。</p><p>首先，我们需要保存get_model()中的模型，并命名为model.pkl。<br>并按照一下文件目录放置文件。Epoch7model.pth为我们保存的一个state，要识别视频，请将测试用的视频文件夹中【一个】视频复制到inputvideo文件夹中。</p><p><img src="/2021/04/19/human-action-video-recognition2/23.JPG" alt="23"></p><p><img src="/2021/04/19/human-action-video-recognition2/24.JPG" alt="24"></p><p>基本操作，定义transform，device,path</p><p><img src="/2021/04/19/human-action-video-recognition2/25.JPG" alt="25"></p><p>move_video和convert和前面基本一致，都是为了移动视频并转换为图片。</p><p><img src="/2021/04/19/human-action-video-recognition2/26.JPG" alt="26"><br>获取视频名称</p><p><img src="/2021/04/19/human-action-video-recognition2/27.JPG" alt="27"></p><p>读取参数导入model。<br>preds为列表，第一项为可能性最高的动作编号，如ApplyEyeMakeup的编号为0，若该动作最有可能是ApplyEyeMakeup，则preds[0]=0，从classes中获取classes[0] = ApplyEyeMakeup</p><p><img src="/2021/04/19/human-action-video-recognition2/28.JPG" alt="28"></p><p>为了下一次识别的需要，在识别后需要将inputvideo和result中的视频图片删除。</p><hr><p>本项目代码解读就此结束，获得的识别准确率、训练测试准确率、loss等数据由于论文尚未发表，暂时不公布。之后会来除个草。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
            <tag> deep-learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Welcome To Chaya&#39;s Blog</title>
      <link href="2021/04/18/WelcomeToMyBlog/"/>
      <url>2021/04/18/WelcomeToMyBlog/</url>
      
        <content type="html"><![CDATA[<p><img src="/2021/04/18/WelcomeToMyBlog/1.jpeg" alt="1"></p><span id="more"></span><h1 id="Readme"><a href="#Readme" class="headerlink" title="Readme"></a>Readme</h1><h2 id="Chaya’s-blog"><a href="#Chaya’s-blog" class="headerlink" title="Chaya’s blog"></a>Chaya’s blog</h2><h3 id="这是Chaya的个人博客，由github-hexo-next搭建，主要用来写一写算法题题解，顺便记录一下平时的生活。"><a href="#这是Chaya的个人博客，由github-hexo-next搭建，主要用来写一写算法题题解，顺便记录一下平时的生活。" class="headerlink" title="这是Chaya的个人博客，由github + hexo +next搭建，主要用来写一写算法题题解，顺便记录一下平时的生活。"></a>这是Chaya的个人博客，由github + hexo +next搭建，主要用来写一写算法题题解，顺便记录一下平时的生活。</h3><p>This is Chaya’s personal blog, builded by github + hexo + next, which is used to record my life and record algorithm problem solution XDD.</p><h3 id="想要了解我的话也可以随意逛逛"><a href="#想要了解我的话也可以随意逛逛" class="headerlink" title="想要了解我的话也可以随意逛逛~"></a>想要了解我的话也可以随意逛逛~</h3><p>If you want to know more about me, just read my blogs ^ ^.</p><h3 id="我的联系方式："><a href="#我的联系方式：" class="headerlink" title="我的联系方式："></a>我的联系方式：</h3><p>Contact me:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Wechat: stonehard0208</span><br><span class="line">Github: https://github.com/stonehard0208</span><br></pre></td></tr></table></figure><p><img src="/2021/04/18/WelcomeToMyBlog/emoji.gif" alt="emoji"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 我的生活 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
